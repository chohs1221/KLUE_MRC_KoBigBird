{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4V1iy8jrUCQR"
   },
   "source": [
    "# Requirments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjNc9QiYxTgK"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7941,
     "status": "ok",
     "timestamp": 1649532146293,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "f1Fm4Dx_xTFK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "from statistics import mean\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import uuid\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForQuestionAnswering, AutoModelForQuestionAnswering, AutoTokenizer, AutoModel, AutoConfig, BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649532146294,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "3Xzif3OL_oAC"
   },
   "outputs": [],
   "source": [
    "for name in 'models', 'submissions':\n",
    "    os.makedirs(name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZI1eMrCRjLY"
   },
   "source": [
    "# Set Arguments, Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649532146294,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "j3W659v9z1Vl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kobigbird_v2_ep2_max1024_lr6e-05_199\n"
     ]
    }
   ],
   "source": [
    "args = edict({'w_project': 'test_project',\n",
    "              'w_entity': 'chohs1221',\n",
    "              'learning_rate': 6e-5,\n",
    "              'batch_size': {'train': 256,\n",
    "                             'eval': 4,\n",
    "                             'test': 256},\n",
    "              'accumulate': 64,\n",
    "              'epochs': 2,\n",
    "              'seed': 42,\n",
    "              # 'model_name': 'monologg/koelectra-base-v3-discriminator',\n",
    "              'model_name': 'monologg/kobigbird-bert-base',\n",
    "              'max_length': 1024})\n",
    "# args['NAME'] = ''f'koelectra_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n",
    "args['NAME'] = ''f'kobigbird_v2_ep{args.epochs}_max{args.max_length}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n",
    "print(args.NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EitWXKJmRw1b",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51HhCeCTTDw5"
   },
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 8124,
     "status": "ok",
     "timestamp": 1649532154412,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "OACaHe-L-P-c",
    "outputId": "cac6c888-231e-490e-d321-718bd3fee890"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20220417_083610-7jj97nnt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chohs1221/test_project/runs/7jj97nnt\" target=\"_blank\">sage-snowball-35</a></strong> to <a href=\"https://wandb.ai/chohs1221/test_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/chohs1221/test_project/runs/7jj97nnt?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f685c6e89a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project = args.w_project, entity = args.w_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649532154413,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "kB3HPxSa-TIn"
   },
   "outputs": [],
   "source": [
    "wandb.run.name = args.NAME\n",
    "wandb.config.learning_rate = args.learning_rate\n",
    "wandb.config.epochs = args.epochs\n",
    "wandb.config.batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6uJSyQCSEoa"
   },
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1649532154413,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "j9b17md7VKba"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbKj9juZVV7W",
    "tags": []
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "a1c035a6c60446a4b443ec729d00e7d7",
      "2679121ae7bd49fab5a9e9f74adc6e6c",
      "00ec2dd9391f4a10826f724ce711d80d",
      "823a62c6238343edbe232263a70289c3",
      "33145eae87e04019aaab299aef0c73df",
      "e3561aeee9c247a1a92c1df34e7ed509",
      "34d1094d406241d682ea8e9b83edd51f",
      "e214ec39d4344afc9ae0d4181fb06398",
      "5c88b5160f23451c9d61fb3a5009b021",
      "f0b50ee2438c45cab7201c8d26fdae40",
      "7bcb8fb2e34f48be860f3863501f843c",
      "ae27d442491940f1ac35f0062fec7983",
      "2ce4afd1875343aea4bc5c7f521b1e5c",
      "bb5f1351c68442449ec3c1b6e8133290",
      "a9e04b9c115b4d4591b227bf2912c774",
      "1b8597a0d76d4128a544701606260406",
      "5779b4e4d0e145f49a0da2a58358c294",
      "bc067dde7c2344eb8d8cfa097a394338",
      "13f5178ac1bc48139f7651840202914b",
      "5ce3e6559dff4b59aae228fdabf5a295",
      "0a90e8a449d54478a024fc48256174ec",
      "5a9d0101f98a48d6a775e4f659eaaa93",
      "86e18552dcb644cea29805c21752ecd3",
      "56aea15e6c624895852ef618d84fe690",
      "c863362dfda543b689aff138d823e73c",
      "547a7ffd4cf24f12bcbaa9f8bb6181a0",
      "38c59a4cf82446938c9c401aceab52db",
      "1d9ec925386947c48a18cf9c52b2e8dc",
      "150d3c4e01d04c96a23db71989ccaf5d",
      "27459b7d3341487bbb3afc098ebea413",
      "c8dd2c501fc3486e8687469421a3eb3c",
      "efbba03209f5470f8503d88b685415aa",
      "c10273b1b6524ccbbb553c6a2e500a2c"
     ]
    },
    "executionInfo": {
     "elapsed": 3588,
     "status": "ok",
     "timestamp": 1649532157991,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "Sm8pjc33VKYg",
    "outputId": "57a0ce23-0357-4fd3-88d6-45af72415018"
   },
   "outputs": [],
   "source": [
    "# tokenizer = ElectraTokenizer.from_pretrained(args.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEQiDROgVXmg",
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBigBirdForStartToken(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    def __init__(self,config):\n",
    "        super().__init__(config)\n",
    "        self.model = AutoModel.from_config(config, add_pooling_layer=False)\n",
    "        self.linear_output = nn.Linear(768, 1)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self,\n",
    "                input_ids = None,\n",
    "                attention_mask = None,\n",
    "                token_type_ids = None):\n",
    "        outputs = self.model(input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n",
    "        \n",
    "        logits = self.linear_output(outputs.last_hidden_state).squeeze(-1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(args.model_name)\n",
    "model = KoBigBirdForStartToken(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KoBigBirdForStartToken(\n",
       "  (model): BigBirdModel(\n",
       "    (embeddings): BigBirdEmbeddings(\n",
       "      (word_embeddings): Embedding(32500, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BigBirdEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear_output): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hCiOQO4VYqM",
    "tags": []
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1649532183383,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "TonS9AsIVQlv"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlKUCHM9SUim",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SPF2-SSVoT5"
   },
   "source": [
    "## Load, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649532183384,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "xoiHRyTOugMj"
   },
   "outputs": [],
   "source": [
    "class KoMRC:\n",
    "    def __init__(self, data, indices: List[Tuple[int, int, int]]):\n",
    "        self._data = data\n",
    "        self._indices = indices\n",
    "\n",
    "\n",
    "    # Json을 불러오는 메소드\n",
    "    @classmethod\n",
    "    def load(cls, file_path: str):\n",
    "        with open(file_path, 'r', encoding='utf-8') as fd:\n",
    "            data = json.load(fd)\n",
    "\n",
    "        indices = []\n",
    "        for d_id, document in enumerate(data['data']):\n",
    "            for p_id, paragraph in enumerate(document['paragraphs']):\n",
    "                for q_id, _ in enumerate(paragraph['qas']):\n",
    "                    indices.append((d_id, p_id, q_id))\n",
    "        \n",
    "        return cls(data, indices)\n",
    "\n",
    "    # Json을 불러오는 메소드\n",
    "    @classmethod\n",
    "    def loads(cls, *file_path: str):\n",
    "        datas = {'data': []}\n",
    "        indices = []\n",
    "        \n",
    "        for f in file_path:\n",
    "            with open(f, 'r', encoding='utf-8') as fd:\n",
    "                data = json.load(fd)\n",
    "            datas['data'] += data['data']\n",
    "            \n",
    "        for d_id, document in enumerate(datas['data']):\n",
    "            for p_id, paragraph in enumerate(document['paragraphs']):\n",
    "                for q_id, _ in enumerate(paragraph['qas']):\n",
    "                    indices.append((d_id, p_id, q_id))\n",
    "\n",
    "        return cls(datas, indices)\n",
    "\n",
    "    # 데이터 셋을 잘라내는 메소드\n",
    "    @classmethod\n",
    "    def split(cls, dataset, eval_ratio: float=.016108):\n",
    "        indices = list(dataset._indices)\n",
    "        random.shuffle(indices)\n",
    "        train_indices = indices[int(len(indices) * eval_ratio):]\n",
    "        eval_indices = indices[:int(len(indices) * eval_ratio)]\n",
    "\n",
    "        return cls(dataset._data, train_indices), cls(dataset._data, eval_indices)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
    "        d_id, p_id, q_id = self._indices[index]\n",
    "        paragraph = self._data['data'][d_id]['paragraphs'][p_id]\n",
    "\n",
    "        qa = paragraph['qas'][q_id]\n",
    "\n",
    "        if 'guid' in qa:\n",
    "            guid = qa['guid']\n",
    "        else:\n",
    "            guid = uuid.uuid4().hex\n",
    "\n",
    "        context = paragraph['context'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n",
    "\n",
    "        question = qa['question'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n",
    "\n",
    "        answers = qa['answers']\n",
    "        if answers != None:\n",
    "            for a in answers:\n",
    "                a['text'] = a['text'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n",
    "        else:\n",
    "            answers = None\n",
    "\n",
    "\n",
    "        return {'guid': guid,\n",
    "            'context': context,\n",
    "            'question': question,\n",
    "            'answers': answers\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1649532185028,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "CDu4gwv_ugKW",
    "outputId": "9f4f4a87-cd03-4fea-f8ee-3bbab3179d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 12037 243425 100268\n"
     ]
    }
   ],
   "source": [
    "dataset1 = KoMRC.load('./datasets2/train.json')\n",
    "dataset2 = KoMRC.load('./datasets2/ko_nia_normal_squad_all.json')\n",
    "dataset3 = KoMRC.load('./datasets2/ko_wiki_v1_squad.json')\n",
    "print(\"Number of Samples:\", len(dataset1), len(dataset2), len(dataset3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaAHVuoEVs32"
   },
   "source": [
    "## Tokenize & Tag Token Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649532185028,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "AluNiOayugGE"
   },
   "outputs": [],
   "source": [
    "class TokenizedKoMRC(KoMRC):\n",
    "    def __init__(self, data, indices: List[Tuple[int, int, int]]) -> None:\n",
    "        super().__init__(data, indices)\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "\n",
    "    def _tokenize_with_position(self, sentence: str) -> List[Tuple[str, Tuple[int, int]]]:\n",
    "        position = 0\n",
    "        tokens = []\n",
    "\n",
    "        sentence_tokens = []\n",
    "        for word in sentence.split():\n",
    "            if '[UNK]' in tokenizer.tokenize(word):\n",
    "                sentence_tokens.append(word)\n",
    "            else:\n",
    "                sentence_tokens += tokenizer.tokenize(word)\n",
    "        \n",
    "        for morph in sentence_tokens:\n",
    "            if len(morph) > 2:\n",
    "                if morph[:2] == '##':\n",
    "                    morph = morph[2:]\n",
    "\n",
    "            position = sentence.find(morph, position)\n",
    "            tokens.append((morph, (position, position + len(morph))))\n",
    "            position += len(morph)\n",
    "            \n",
    "        return tokens\n",
    "            \n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
    "        sample = super().__getitem__(index)\n",
    "        # sample = {'guid': guid, 'context': context, 'question': question, 'answers': answers}\n",
    "\n",
    "        context, position = zip(*self._tokenize_with_position(sample['context']))\n",
    "        context, position = list(context), list(position)\n",
    "\n",
    "        question = self._tokenizer.tokenize(sample['question'])\n",
    "\n",
    "        if sample['answers'] is not None:\n",
    "            answers = []\n",
    "            for answer in sample['answers']:\n",
    "                for start, (position_start, position_end) in enumerate(position):\n",
    "                    if position_start <= answer['answer_start'] < position_end:\n",
    "                        break\n",
    "                else:\n",
    "                    print(context, answer)\n",
    "                    print(answer['guid'])\n",
    "                    print(answer['answer_start'])\n",
    "                    raise ValueError(\"No mathced start position\")\n",
    "\n",
    "                target = ''.join(answer['text'].split(' '))\n",
    "                source = ''\n",
    "                for end, morph in enumerate(context[start:], start):\n",
    "                    source += morph\n",
    "                    if target in source:\n",
    "                        break\n",
    "                else:\n",
    "                    print(context, answer)\n",
    "                    print(answer['guid'])\n",
    "                    print(answer['answer_start'])\n",
    "                    raise ValueError(\"No Matched end position\")\n",
    "\n",
    "                answers.append({'start': start, 'end': end})\n",
    "            answer_text = sample['answers'][0]['text']\n",
    "\n",
    "        else:\n",
    "            answers = None\n",
    "            answer_text = None\n",
    "        \n",
    "        return {\n",
    "            'guid': sample['guid'],\n",
    "            'context_original': sample['context'],\n",
    "            'context_position': position,\n",
    "            'question_original': sample['question'],\n",
    "            'context': context,\n",
    "            'question': question,\n",
    "            'answers': answers,\n",
    "            'answers_text': answer_text\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1649532185632,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "K3Cu4vU1ugD2",
    "outputId": "0b7c594e-aebd-4782-c069-8b2f150d1ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Samples: 350000\n",
      "Number of Dev Samples: 5730\n"
     ]
    }
   ],
   "source": [
    "dataset = TokenizedKoMRC.loads('./datasets2/train.json', './datasets2/ko_nia_normal_squad_all.json', './datasets2/ko_wiki_v1_squad.json')\n",
    "train_dataset, dev_dataset = TokenizedKoMRC.split(dataset)\n",
    "# dataset = TokenizedKoMRC.load('./datasets2/train.json')\n",
    "# train_dataset, dev_dataset = TokenizedKoMRC.split(dataset, eval_ratio=0.1)\n",
    "# train_dataset, dev_dataset = TokenizedKoMRC.split(dev_dataset, eval_ratio=0.1)\n",
    "\n",
    "dev_answers = [dev_dataset[i]['answers_text'] for i in range(len(dev_dataset))]\n",
    "\n",
    "print(\"Number of Train Samples:\", len(train_dataset))\n",
    "print(\"Number of Dev Samples:\", len(dev_dataset))\n",
    "# print(sample['context'][sample['answers'][0]['start']:sample['answers'][0]['end']+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQ6g-qhV_7g"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649532185633,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "GyN44Vg-uf-Y"
   },
   "outputs": [],
   "source": [
    "class Indexer:\n",
    "    def __init__(self, vocabs: List[str], max_length: int=args.max_length):\n",
    "        self.max_length = max_length\n",
    "        self.vocabs = vocabs\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocabs)\n",
    "    @property\n",
    "    def pad_id(self):\n",
    "        return tokenizer.vocab['[PAD]']\n",
    "    @property\n",
    "    def unk_id(self):\n",
    "        return tokenizer.vocab['[UNK]']\n",
    "    @property\n",
    "    def cls_id(self):\n",
    "        return tokenizer.vocab['[CLS]']\n",
    "    @property\n",
    "    def sep_id(self):\n",
    "        return tokenizer.vocab['[SEP]']\n",
    "\n",
    "\n",
    "    def sample2ids(self, sample: Dict[str, Any],) -> Dict[str, Any]:\n",
    "        context = [tokenizer.convert_tokens_to_ids(token) for token in sample['context']]\n",
    "        question = [tokenizer.convert_tokens_to_ids(token) for token in sample['question']]\n",
    "\n",
    "        context = context[:self.max_length-len(question)-3]             # Truncate context\n",
    "        \n",
    "        input_ids = [self.cls_id] + question + [self.sep_id] + context + [self.sep_id]\n",
    "        token_type_ids = [0] * (len(question) + 1) + [1] * (len(context) + 2)\n",
    "\n",
    "        if sample['answers'] is not None:\n",
    "            answer = sample['answers'][0]\n",
    "            start = min(len(question) + 2 + answer['start'], self.max_length - 1)\n",
    "            end = min(len(question) + 2 + answer['end'], self.max_length - 1)\n",
    "        else:\n",
    "            start = None\n",
    "            end = None\n",
    "\n",
    "        return {\n",
    "            'guid': sample['guid'],\n",
    "            'context': sample['context_original'],\n",
    "            'question': sample['question_original'],\n",
    "            'position': sample['context_position'],\n",
    "            'input_ids': input_ids,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'start': start,\n",
    "            'end': end\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649532185633,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "grrjgBHWuf8H",
    "outputId": "edd0759e-f473-4dd9-b9db-3f516f2be6c8"
   },
   "outputs": [],
   "source": [
    "indexer = Indexer(list(tokenizer.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gLlDcdhWMVy"
   },
   "source": [
    "## Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649532185633,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "R2nGyyJLuf54"
   },
   "outputs": [],
   "source": [
    "class IndexerWrappedDataset:\n",
    "    def __init__(self, dataset: TokenizedKoMRC, indexer: Indexer) -> None:\n",
    "        self._dataset = dataset\n",
    "        self._indexer = indexer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._dataset)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
    "        sample = self._indexer.sample2ids(self._dataset[index])\n",
    "        sample['attention_mask'] = [1] * len(sample['input_ids'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1649532186061,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "g5ee_MDquf3p",
    "outputId": "1f8ce936-5665-4d6f-864c-d03db8cbe338"
   },
   "outputs": [],
   "source": [
    "indexed_train_dataset = IndexerWrappedDataset(train_dataset, indexer)\n",
    "indexed_dev_dataset = IndexerWrappedDataset(dev_dataset, indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexed_train_dataset[0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrnFWwNFWydX"
   },
   "source": [
    "## Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649532186061,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "Pp4TTU5Oufy-"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    def __init__(self, indexer: Indexer) -> None:\n",
    "        self._indexer = indexer\n",
    "\n",
    "\n",
    "    def __call__(self, samples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        samples = {key: [sample[key] for sample in samples] for key in samples[0]}\n",
    "\n",
    "        for key in 'start', 'end':\n",
    "            if samples[key][0] is None:\n",
    "                samples[key] = None\n",
    "            else:\n",
    "                samples[key] = torch.tensor(samples[key], dtype=torch.long)\n",
    "        \n",
    "        for key in 'input_ids', 'attention_mask', 'token_type_ids':\n",
    "            samples[key] = pad_sequence([torch.tensor(sample, dtype=torch.long) for sample in samples[key]],\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=self._indexer.pad_id)\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNj_C_6sSwpE"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649532186061,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "SlVyogmMufwZ"
   },
   "outputs": [],
   "source": [
    "collator = Collator(indexer)\n",
    "train_loader = DataLoader(indexed_train_dataset,\n",
    "                          batch_size = args.batch_size.train // args.accumulate,\n",
    "                          shuffle = True,\n",
    "                          collate_fn = collator,\n",
    "                          num_workers = 2)\n",
    "\n",
    "dev_loader = DataLoader(indexed_dev_dataset,\n",
    "                        batch_size = args.batch_size.eval,\n",
    "                        shuffle = False,\n",
    "                        collate_fn = collator,\n",
    "                        num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1649532186561,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "3lcvlUltufuC",
    "outputId": "8bdf541f-6e03-41c0-fe6c-a6fdfe080842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 471])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch['input_ids'].size()\n",
    "# batch = next(iter(dev_loader))\n",
    "# print(batch['input_ids'])\n",
    "# print(batch['input_ids'].shape)\n",
    "# print(list(batch.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8bJH_DNRfVm"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAfQOTuPeuWN",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Empty Cuda Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1649532186562,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "6WREvLj-AARp"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tkYfToDenKV",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfm5X-bEufpW",
    "outputId": "b68c37ae-18c2-412e-8adb-37f3a9ecd227",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ===============================================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cd7df7700348ca962c1accc22e8a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=87500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 660 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "\n",
    "train_loss = []\n",
    "dev_loss = []\n",
    "\n",
    "loss_accumulate = 0.\n",
    "\n",
    "best_model = [-1, int(1e9)]\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"Epoch\", epoch, '===============================================================================================================')\n",
    "\n",
    "    # Train    \n",
    "    progress_bar_train = tqdm(train_loader, desc='Train')\n",
    "    for i, batch in enumerate(progress_bar_train, 1):\n",
    "        del batch['guid'], batch['context'], batch['question'], batch['position']\n",
    "        batch = {key: value.cuda() for key, value in batch.items()}\n",
    "        \n",
    "        start = batch.pop('start')\n",
    "        end = batch.pop('end')\n",
    "        \n",
    "        output = model(**batch)\n",
    "        \n",
    "        loss = F.cross_entropy(output, end) / args.accumulate\n",
    "        loss.backward()\n",
    "\n",
    "        loss_accumulate += loss.item()\n",
    "\n",
    "        del batch, start, end, output, loss\n",
    "        \n",
    "        if i % args.accumulate == 0:\n",
    "            # clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=False)\n",
    "\n",
    "            train_loss.append(loss_accumulate)\n",
    "            progress_bar_train.set_description(f\"Train - Loss: {loss_accumulate:.3f}\")\n",
    "            loss_accumulate = 0.\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if (i // args.accumulate) % (int(len(train_loader) / (args.accumulate * 25))+1) == 0:\n",
    "            # Evaluation\n",
    "            for batch in dev_loader:\n",
    "                del batch['guid'], batch['context'], batch['question'], batch['position']\n",
    "                batch = {key: value.cuda() for key, value in batch.items()}\n",
    "\n",
    "                start = batch.pop('start')\n",
    "                end = batch.pop('end')\n",
    "                \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    output = model(**batch)\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "                loss = F.cross_entropy(output, end)\n",
    "\n",
    "                dev_loss.append(loss.item())\n",
    "\n",
    "                del batch, start, end, output, loss\n",
    "\n",
    "            train_losses.append(mean(train_loss))\n",
    "            dev_losses.append(mean(dev_loss))\n",
    "            train_loss = []\n",
    "            dev_loss = []\n",
    "\n",
    "            \n",
    "            if dev_losses[-1] <= best_model[1]:\n",
    "                best_model = (epoch, dev_losses[-1])\n",
    "                model.save_pretrained(f'models/{args.NAME}_{epoch}')\n",
    "                \n",
    "            wandb.log({\"train_loss\": train_losses[-1], \n",
    "                       \"valid_loss\": dev_losses[-1]})\n",
    "            \n",
    "    print(f\"Train Loss: {train_losses[-1]:.3f}\")\n",
    "    print(f\"Valid Loss: {dev_losses[-1]:.3f}\")\n",
    "    print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NeU3ogjS2LZ",
    "tags": []
   },
   "source": [
    "## Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nDxYe7KufnH"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(dev_losses, label=\"Dev Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJKrztCmXRBB"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4vjm5TrYP-S"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5f9hR0qsu9Ap"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Samples 4008\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TokenizedKoMRC.load('./datasets2/test.json')\n",
    "indexer_test = Indexer(list(tokenizer.vocab.keys()))\n",
    "indexed_test_dataset = IndexerWrappedDataset(test_dataset, indexer_test)\n",
    "print(\"Number of Test Samples\", len(test_dataset))\n",
    "# print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8js2FfYYJR7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nESvW3pKufkv"
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(f'models/{args.NAME}_{best_model[0]}')\n",
    "model1 = KoBigBirdForStartToken(config)\n",
    "model1.cuda();\n",
    "\n",
    "config = AutoConfig.from_pretrained(f'models/kobigbird_v2_ep2_max1024_lr6e-05_637_1')\n",
    "model2 = KoBigBirdForStartToken(config)\n",
    "model2.cuda();\n",
    "# summary(model, (args.batch_size.train//args.accumulate, args.max_length), dtypes=['torch.IntTensor'], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbM5uvjDufiJ"
   },
   "outputs": [],
   "source": [
    "for idx, sample in zip(range(1, 4), indexed_train_dataset):\n",
    "    print(f'------{idx}------')\n",
    "    print('Context:', sample['context'])\n",
    "    print('Question:', sample['question'])\n",
    "    \n",
    "    input_ids, token_type_ids = [\n",
    "        torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
    "        for key in (\"input_ids\", \"token_type_ids\")\n",
    "    ]\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        output1 = model1(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
    "        output2 = model2(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
    "\n",
    "    output1.squeeze_(0), output2.squeeze_(0)\n",
    "    \n",
    "    start_prob = output1[token_type_ids.bool()][1:-1].softmax(-1)\n",
    "    end_prob = output2[token_type_ids.bool()][1:-1].softmax(-1)\n",
    "\n",
    "    probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
    "\n",
    "    index = torch.argmax(probability).item()\n",
    "    \n",
    "    start = index // len(end_prob)\n",
    "    end = index % len(end_prob)\n",
    "    \n",
    "    start_str = sample['position'][start][0]\n",
    "    end_str = sample['position'][end][1]\n",
    "\n",
    "    print('Answer:', sample['context'][start_str:end_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_visualize = []\n",
    "end_visualize = []\n",
    "\n",
    "dev_prediction = []\n",
    "# for sample in tqdm(test_dataset, \"Testing\"):\n",
    "for sample in tqdm(indexed_dev_dataset, \"Testing\"):\n",
    "    input_ids, token_type_ids = [torch.tensor(sample[key], dtype=torch.long, device=\"cuda\") for key in (\"input_ids\", \"token_type_ids\")]\n",
    "    # print(sample)\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        output1 = model1(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
    "        output2 = model2(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
    "\n",
    "    output1.squeeze_(0), output2.squeeze_(0)\n",
    "    \n",
    "    start_prob = output1[token_type_ids.bool()][1:-1].softmax(-1)\n",
    "    end_prob = output2[token_type_ids.bool()][1:-1].softmax(-1)\n",
    "\n",
    "    probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
    "\n",
    "    # 토큰 길이 8까지만\n",
    "    for row in range(len(start_prob) - 8):\n",
    "        probability[row] = torch.cat((probability[row][:8+row].cpu(), torch.Tensor([0] * (len(start_prob)-(8+row))).cpu()), 0)\n",
    "\n",
    "    index = torch.argmax(probability).item()\n",
    "\n",
    "    start = index // len(end_prob)\n",
    "    end = index % len(end_prob)\n",
    "\n",
    "    # 확률 너무 낮으면 자르기\n",
    "    if start_prob[start] >= 0 or end_prob[end] >= 0:\n",
    "        start_str = sample['position'][start][0]\n",
    "        end_str = sample['position'][end][1]\n",
    "    else:\n",
    "        start_str = 0\n",
    "        end_str = 0\n",
    "\n",
    "    start_visualize.append((list(start_prob.cpu()), (start, end), (start_str, end_str)))\n",
    "    end_visualize.append((list(end_prob.cpu()), (start, end), (start_str, end_str)))\n",
    "\n",
    "    dev_prediction.append([sample[\"guid\"], sample['context'][start_str:end_str]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lenvenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(a, b):\n",
    "    ''' 레벤슈타인 거리 계산하기 '''\n",
    "    if a == b:\n",
    "        return 0 # 같으면 0을 반환\n",
    "    \n",
    "    a_len = len(a) # a 길이\n",
    "    b_len = len(b) # b 길이\n",
    "    if a == \"\":\n",
    "        return b_len\n",
    "    if b == \"\":\n",
    "        return a_len\n",
    "    \n",
    "    matrix = [[] for i in range(a_len+1)]\n",
    "    \n",
    "    for i in range(a_len+1): # 0으로 초기화\n",
    "        matrix[i] = [0 for j in range(b_len+1)]\n",
    "        \n",
    "    # 0일 때 초깃값을 설정\n",
    "    for i in range(a_len+1):\n",
    "        matrix[i][0] = i\n",
    "        \n",
    "    for j in range(b_len+1):\n",
    "        matrix[0][j] = j\n",
    "        \n",
    "    # 표 채우기 --- (※2)\n",
    "    for i in range(1, a_len+1):\n",
    "        ac = a[i-1]\n",
    "        for j in range(1, b_len+1):\n",
    "            bc = b[j-1]\n",
    "            cost = 0 if (ac == bc) else 1\n",
    "            matrix[i][j] = min([\n",
    "                matrix[i-1][j] + 1,     # 문자 삽입\n",
    "                matrix[i][j-1] + 1,     # 문자 제거\n",
    "                matrix[i-1][j-1] + cost # 문자 변경\n",
    "            ])\n",
    "            \n",
    "    return matrix[a_len][b_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(int(len(dev_answers))):\n",
    "    s = calc_distance(dev_prediction[i], dev_answers[i][0])\n",
    "    score.append(s)\n",
    "mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul-FlUBZY88_"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyVG3J2hu8-s"
   },
   "outputs": [],
   "source": [
    "start_visualize = []\n",
    "end_visualize = []\n",
    "\n",
    "with torch.no_grad(), open(f'submissions/{args.NAME}.csv', 'w') as fd:\n",
    "    writer = csv.writer(fd)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "\n",
    "    rows = []\n",
    "    # for sample in tqdm(test_dataset, \"Testing\"):\n",
    "    for sample in tqdm(indexed_test_dataset, \"Testing\"):\n",
    "        input_ids, token_type_ids = [torch.tensor(sample[key], dtype=torch.long, device=\"cuda\") for key in (\"input_ids\", \"token_type_ids\")]\n",
    "        # print(sample)\n",
    "    \n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "        with torch.no_grad():\n",
    "            output1 = model1(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
    "            output2 = model2(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
    "\n",
    "        output1.squeeze_(0), output2.squeeze_(0)\n",
    "\n",
    "        start_prob = output1[token_type_ids.bool()][1:-1].softmax(-1)\n",
    "        end_prob = output2[token_type_ids.bool()][1:-1].softmax(-1)\n",
    "\n",
    "        probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
    "\n",
    "        # 토큰 길이 8까지만\n",
    "        for row in range(len(start_prob) - 8):\n",
    "            probability[row] = torch.cat((probability[row][:8+row].cpu(), torch.Tensor([0] * (len(start_prob)-(8+row))).cpu()), 0)\n",
    "\n",
    "        index = torch.argmax(probability).item()\n",
    "\n",
    "        start = index // len(end_prob)\n",
    "        end = index % len(end_prob)\n",
    "        \n",
    "        # 확률 너무 낮으면 자르기\n",
    "        if start_prob[start] >= 0 or end_prob[end] >= 0:\n",
    "            start_str = sample['position'][start][0]\n",
    "            end_str = sample['position'][end][1]\n",
    "        else:\n",
    "            start_str = 0\n",
    "            end_str = 0\n",
    "\n",
    "        start_visualize.append((list(start_prob.cpu()), (start, end), (start_str, end_str)))\n",
    "        end_visualize.append((list(end_prob.cpu()), (start, end), (start_str, end_str)))\n",
    "        \n",
    "        rows.append([sample[\"guid\"], sample['context'][start_str:end_str]])\n",
    "\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPPqI+M8NOhzknxVU85TvZb",
   "background_execution": "on",
   "collapsed_sections": [
    "F6uJSyQCSEoa",
    "YbKj9juZVV7W",
    "9hCiOQO4VYqM",
    "MlKUCHM9SUim",
    "eAfQOTuPeuWN"
   ],
   "machine_shape": "hm",
   "mount_file_id": "1D0oyh8a84WvhSLt-DAyn0S1JG4aNFg6n",
   "name": "baselinecode_fixing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ec2dd9391f4a10826f724ce711d80d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e214ec39d4344afc9ae0d4181fb06398",
      "max": 263326,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c88b5160f23451c9d61fb3a5009b021",
      "value": 263326
     }
    },
    "0458f51b68e345c481afcfedebd28da7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3ee09dbae5b419aa5dca8280991917a",
       "IPY_MODEL_21aaf3c8d96d41c78ba0f9f9b3fb799e",
       "IPY_MODEL_c0ed98ff850f49cea8aaac5bdfd397f9"
      ],
      "layout": "IPY_MODEL_58706e9bade3490cad47b6a42f010da6"
     }
    },
    "0a90e8a449d54478a024fc48256174ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13f5178ac1bc48139f7651840202914b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "150d3c4e01d04c96a23db71989ccaf5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b8597a0d76d4128a544701606260406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d9ec925386947c48a18cf9c52b2e8dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21aaf3c8d96d41c78ba0f9f9b3fb799e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33462c9795984bc6893f33998611a748",
      "max": 451741507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77c8c54416f94386b69153897b83f2f0",
      "value": 451741507
     }
    },
    "2679121ae7bd49fab5a9e9f74adc6e6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3561aeee9c247a1a92c1df34e7ed509",
      "placeholder": "​",
      "style": "IPY_MODEL_34d1094d406241d682ea8e9b83edd51f",
      "value": "Downloading: 100%"
     }
    },
    "27459b7d3341487bbb3afc098ebea413": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ce4afd1875343aea4bc5c7f521b1e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5779b4e4d0e145f49a0da2a58358c294",
      "placeholder": "​",
      "style": "IPY_MODEL_bc067dde7c2344eb8d8cfa097a394338",
      "value": "Downloading: 100%"
     }
    },
    "33145eae87e04019aaab299aef0c73df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33462c9795984bc6893f33998611a748": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34d1094d406241d682ea8e9b83edd51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34e6307be5cd4217a1f6daf995d58055": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38c59a4cf82446938c9c401aceab52db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50f084ad7ed34f61b78cac60e521d5dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "547a7ffd4cf24f12bcbaa9f8bb6181a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efbba03209f5470f8503d88b685415aa",
      "placeholder": "​",
      "style": "IPY_MODEL_c10273b1b6524ccbbb553c6a2e500a2c",
      "value": " 467/467 [00:00&lt;00:00, 21.5kB/s]"
     }
    },
    "56aea15e6c624895852ef618d84fe690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d9ec925386947c48a18cf9c52b2e8dc",
      "placeholder": "​",
      "style": "IPY_MODEL_150d3c4e01d04c96a23db71989ccaf5d",
      "value": "Downloading: 100%"
     }
    },
    "5779b4e4d0e145f49a0da2a58358c294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58706e9bade3490cad47b6a42f010da6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a9d0101f98a48d6a775e4f659eaaa93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c88b5160f23451c9d61fb3a5009b021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ce3e6559dff4b59aae228fdabf5a295": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77c8c54416f94386b69153897b83f2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bcb8fb2e34f48be860f3863501f843c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "823a62c6238343edbe232263a70289c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0b50ee2438c45cab7201c8d26fdae40",
      "placeholder": "​",
      "style": "IPY_MODEL_7bcb8fb2e34f48be860f3863501f843c",
      "value": " 257k/257k [00:00&lt;00:00, 601kB/s]"
     }
    },
    "86e18552dcb644cea29805c21752ecd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56aea15e6c624895852ef618d84fe690",
       "IPY_MODEL_c863362dfda543b689aff138d823e73c",
       "IPY_MODEL_547a7ffd4cf24f12bcbaa9f8bb6181a0"
      ],
      "layout": "IPY_MODEL_38c59a4cf82446938c9c401aceab52db"
     }
    },
    "a1c035a6c60446a4b443ec729d00e7d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2679121ae7bd49fab5a9e9f74adc6e6c",
       "IPY_MODEL_00ec2dd9391f4a10826f724ce711d80d",
       "IPY_MODEL_823a62c6238343edbe232263a70289c3"
      ],
      "layout": "IPY_MODEL_33145eae87e04019aaab299aef0c73df"
     }
    },
    "a9e04b9c115b4d4591b227bf2912c774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a90e8a449d54478a024fc48256174ec",
      "placeholder": "​",
      "style": "IPY_MODEL_5a9d0101f98a48d6a775e4f659eaaa93",
      "value": " 61.0/61.0 [00:00&lt;00:00, 2.70kB/s]"
     }
    },
    "ae27d442491940f1ac35f0062fec7983": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ce4afd1875343aea4bc5c7f521b1e5c",
       "IPY_MODEL_bb5f1351c68442449ec3c1b6e8133290",
       "IPY_MODEL_a9e04b9c115b4d4591b227bf2912c774"
      ],
      "layout": "IPY_MODEL_1b8597a0d76d4128a544701606260406"
     }
    },
    "b3ee09dbae5b419aa5dca8280991917a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcc54673c0c346b5a4ef3adacee3b7c6",
      "placeholder": "​",
      "style": "IPY_MODEL_34e6307be5cd4217a1f6daf995d58055",
      "value": "Downloading: 100%"
     }
    },
    "bb5f1351c68442449ec3c1b6e8133290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13f5178ac1bc48139f7651840202914b",
      "max": 61,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ce3e6559dff4b59aae228fdabf5a295",
      "value": 61
     }
    },
    "bc067dde7c2344eb8d8cfa097a394338": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c00888417b344194847378c9424cafd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0ed98ff850f49cea8aaac5bdfd397f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c00888417b344194847378c9424cafd4",
      "placeholder": "​",
      "style": "IPY_MODEL_50f084ad7ed34f61b78cac60e521d5dc",
      "value": " 431M/431M [00:08&lt;00:00, 67.7MB/s]"
     }
    },
    "c10273b1b6524ccbbb553c6a2e500a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c863362dfda543b689aff138d823e73c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27459b7d3341487bbb3afc098ebea413",
      "max": 467,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8dd2c501fc3486e8687469421a3eb3c",
      "value": 467
     }
    },
    "c8dd2c501fc3486e8687469421a3eb3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dcc54673c0c346b5a4ef3adacee3b7c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e214ec39d4344afc9ae0d4181fb06398": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3561aeee9c247a1a92c1df34e7ed509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efbba03209f5470f8503d88b685415aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b50ee2438c45cab7201c8d26fdae40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
